title: 机器学习与R(9)-k nearest neighbors-2
date: 2014-08-22 19:46:35
category: 数据科学
tags: [数据科学,机器学习,R,机器学习与R]
---

利用kNN算法来诊断乳腺癌

## 背景

乳腺癌的早期检测来源对乳腺异常包块的检测。如果存在包块，那么会继续乳腺穿刺取样，之后利用显微镜下的分析来判断是良性还是恶性。如果我们可以用机器学习来完成癌症细胞的自动识别则我们可以为健康系统带来大大好处，比如检测效率的提升。同时自动的筛选系统可以大大减少人工的主观性。

## 数据准备

这里我们使用Breast Cancer Wisconsin Diagnostic数据集，你可以从[这里](http://mlr.cs.umass.edu/ml/machine-learning-databases/breast-cancer-wisconsin/wdbc.data)下载它，数据说明[点击这里](http://mlr.cs.umass.edu/ml/machine-learning-databases/breast-cancer-wisconsin/wdbc.names)。

数据包含了569个样本，32个特征的数据，其中关键特征为:

+ Radius
+ Texture
+ Perimeter
+ Area
+ Smoothness
+ Compactness
+ Concavity
+ Concave points
+ Symmetry
+ Fractal dimension

数据分别度量了这些特征的均值，标准差，以及最大值，在数据集中依次为3～12，13～22，23～32列。第1列为id，第2列为诊断结果，`B`为良性，`M`为恶性。


```r
wdbc = read.csv("wdbc.data", header = F)
wdbc.names = c("Radius", "Texture", "Perimeter", "Area", "Smoothness", "Compactness", 
    "Concavity", "Concave points", "Symmetry", "Fractal dimension")
wdbc.names = c(wdbc.names, paste(wdbc.names, "_mean", sep = ""), paste(wdbc.names, 
    "_worst", sep = ""))
names(wdbc) = c("id", "diagnosis", wdbc.names)
```


最终的数据为：


```r
str(wdbc)
```

```
## 'data.frame':	569 obs. of  32 variables:
##  $ id                     : int  842302 842517 84300903 84348301 84358402 843786 844359 84458202 844981 84501001 ...
##  $ diagnosis              : Factor w/ 2 levels "B","M": 2 2 2 2 2 2 2 2 2 2 ...
##  $ Radius                 : num  18 20.6 19.7 11.4 20.3 ...
##  $ Texture                : num  10.4 17.8 21.2 20.4 14.3 ...
##  $ Perimeter              : num  122.8 132.9 130 77.6 135.1 ...
##  $ Area                   : num  1001 1326 1203 386 1297 ...
##  $ Smoothness             : num  0.1184 0.0847 0.1096 0.1425 0.1003 ...
##  $ Compactness            : num  0.2776 0.0786 0.1599 0.2839 0.1328 ...
##  $ Concavity              : num  0.3001 0.0869 0.1974 0.2414 0.198 ...
##  $ Concave points         : num  0.1471 0.0702 0.1279 0.1052 0.1043 ...
##  $ Symmetry               : num  0.242 0.181 0.207 0.26 0.181 ...
##  $ Fractal dimension      : num  0.0787 0.0567 0.06 0.0974 0.0588 ...
##  $ Radius_mean            : num  1.095 0.543 0.746 0.496 0.757 ...
##  $ Texture_mean           : num  0.905 0.734 0.787 1.156 0.781 ...
##  $ Perimeter_mean         : num  8.59 3.4 4.58 3.44 5.44 ...
##  $ Area_mean              : num  153.4 74.1 94 27.2 94.4 ...
##  $ Smoothness_mean        : num  0.0064 0.00522 0.00615 0.00911 0.01149 ...
##  $ Compactness_mean       : num  0.049 0.0131 0.0401 0.0746 0.0246 ...
##  $ Concavity_mean         : num  0.0537 0.0186 0.0383 0.0566 0.0569 ...
##  $ Concave points_mean    : num  0.0159 0.0134 0.0206 0.0187 0.0188 ...
##  $ Symmetry_mean          : num  0.03 0.0139 0.0225 0.0596 0.0176 ...
##  $ Fractal dimension_mean : num  0.00619 0.00353 0.00457 0.00921 0.00511 ...
##  $ Radius_worst           : num  25.4 25 23.6 14.9 22.5 ...
##  $ Texture_worst          : num  17.3 23.4 25.5 26.5 16.7 ...
##  $ Perimeter_worst        : num  184.6 158.8 152.5 98.9 152.2 ...
##  $ Area_worst             : num  2019 1956 1709 568 1575 ...
##  $ Smoothness_worst       : num  0.162 0.124 0.144 0.21 0.137 ...
##  $ Compactness_worst      : num  0.666 0.187 0.424 0.866 0.205 ...
##  $ Concavity_worst        : num  0.712 0.242 0.45 0.687 0.4 ...
##  $ Concave points_worst   : num  0.265 0.186 0.243 0.258 0.163 ...
##  $ Symmetry_worst         : num  0.46 0.275 0.361 0.664 0.236 ...
##  $ Fractal dimension_worst: num  0.1189 0.089 0.0876 0.173 0.0768 ...
```


从这里我们知道数据集中357个样本为良性，212个为恶性肿瘤


```r
table(wdbc$diagnosis)
```

```
## 
##   B   M 
## 357 212
```


这里我们再修改一下数据,同时去掉id，因为id对预测没有意义：


```r
wdbc$diagnosis = factor(wdbc$diagnosis, levels = c("B", "M"), labels = c("Benign", 
    "Malignant"))
round(prop.table(table(wdbc$diagnosis)) * 100, digits = 1)
```

```
## 
##    Benign Malignant 
##      62.7      37.3
```

```r
wdbc = wdbc[-1]
```


通过`summary`，我们很明显看出不同的特征的度量值差别太大：


```r
summary(wdbc[c("Radius_mean", "Area_mean", "Smoothness_mean")])
```

```
##   Radius_mean      Area_mean     Smoothness_mean  
##  Min.   :0.112   Min.   :  6.8   Min.   :0.00171  
##  1st Qu.:0.232   1st Qu.: 17.9   1st Qu.:0.00517  
##  Median :0.324   Median : 24.5   Median :0.00638  
##  Mean   :0.405   Mean   : 40.3   Mean   :0.00704  
##  3rd Qu.:0.479   3rd Qu.: 45.2   3rd Qu.:0.00815  
##  Max.   :2.873   Max.   :542.2   Max.   :0.03113
```


## 数据转换

显然数据需要转换,我们定义转换函数为：


```r
normalize <- function(x) {
    return((x - min(x))/(max(x) - min(x)))
}
```



接下来对数据进行转换后，执行`summary`可以看出特征的区间分布已经统一了：


```r
wdbc_n <- as.data.frame(lapply(wdbc[2:31], normalize))
summary(wdbc_n[c("Radius_mean", "Area_mean", "Smoothness_mean")])
```

```
##   Radius_mean       Area_mean      Smoothness_mean
##  Min.   :0.0000   Min.   :0.0000   Min.   :0.000  
##  1st Qu.:0.0438   1st Qu.:0.0206   1st Qu.:0.117  
##  Median :0.0770   Median :0.0331   Median :0.159  
##  Mean   :0.1063   Mean   :0.0626   Mean   :0.181  
##  3rd Qu.:0.1330   3rd Qu.:0.0717   3rd Qu.:0.219  
##  Max.   :1.0000   Max.   :1.0000   Max.   :1.000
```


接下来我们需要构造训练数据与测试数据，实际通常的做法是training,validation,test三个数据集，validataion用来校正提高模型准确性。这里简单起见我们只用train和test数据集，最简单的方法是如下：


```r
wdbc_train = wdbc_n[1:469, ]
wdbc_test = wdbc_n[470:569, ]
wdbc_train_label = wdbc[1:469, 1]
wdbc_test_label = wdbc[470:569, 1]
mal_rate = table(wdbc_train_label)
round(mal_rate[2]/sum(mal_rate), digits = 2)
```

```
## Malignant 
##       0.4
```


这个方法虽然简单，但需要注意这里我们不是随机采样，如果样本中的恶性肿瘤大部分布在1：469显然就有很大问题。当然另一种方法就是用`sample`函数，例如：


```r
set.seed(2014)
inTrain = sample(1:dim(wdbc_n)[1], 469, replace = F)
wdbc_train = wdbc_n[inTrain, ]
wdbc_test = wdbc_n[-inTrain, ]
wdbc_train_label = wdbc[inTrain, 1]
wdbc_test_label = wdbc[-inTrain, 1]
mal_rate = table(wdbc_train_label)
round(mal_rate[2]/sum(mal_rate), digits = 2)
```

```
## Malignant 
##      0.37
```


除此之外，个人常用`caret`包的`createDataPartition`来完成这一工作：


```r
require(caret)
```

```
## Loading required package: caret
```

```
## Warning: package 'caret' was built under R version 3.0.3
```

```
## Loading required package: lattice
## Loading required package: ggplot2
```

```r
set.seed(2014)
inTrain = createDataPartition(y = wdbc$diagnosis, p = 0.8, list = FALSE)
wdbc_train = wdbc_n[inTrain, ]
wdbc_test = wdbc_n[-inTrain, ]
wdbc_train_label = wdbc[inTrain, 1]
wdbc_test_label = wdbc[-inTrain, 1]
mal_rate = table(wdbc_train_label)
round(mal_rate[2]/sum(mal_rate), digits = 2)
```

```
## Malignant 
##      0.37
```


## 构建模型

这里kNN实现，我们采用`class`包的实现，当然其他实现你可以参考CRAN。


```r
require(class)
```

```
## Loading required package: class
```

```r
wdbc_test_pred <- knn(train = wdbc_train, test = wdbc_test, cl = wdbc_train_label, 
    k = 21)
```


这里k=21，基于是采用`length(wdbc_train_label)`的平方根。`knn`的使用说明如下：

+ train: 训练数据
+ test: 测试数据
+ cl: factor,训练数据的对应分类

## 模型评估

这里采用`gmodels`的`CrossTable`函数


```r
require(gmodels)
```

```
## Loading required package: gmodels
```

```
## Warning: package 'gmodels' was built under R version 3.0.3
```

```r
CrossTable(x = wdbc_test_label, y = wdbc_test_pred, prop.chisq = FALSE)
```

```
## 
##  
##    Cell Contents
## |-------------------------|
## |                       N |
## |           N / Row Total |
## |           N / Col Total |
## |         N / Table Total |
## |-------------------------|
## 
##  
## Total Observations in Table:  113 
## 
##  
##                 | wdbc_test_pred 
## wdbc_test_label |    Benign | Malignant | Row Total | 
## ----------------|-----------|-----------|-----------|
##          Benign |        71 |         0 |        71 | 
##                 |     1.000 |     0.000 |     0.628 | 
##                 |     0.959 |     0.000 |           | 
##                 |     0.628 |     0.000 |           | 
## ----------------|-----------|-----------|-----------|
##       Malignant |         3 |        39 |        42 | 
##                 |     0.071 |     0.929 |     0.372 | 
##                 |     0.041 |     1.000 |           | 
##                 |     0.027 |     0.345 |           | 
## ----------------|-----------|-----------|-----------|
##    Column Total |        74 |        39 |       113 | 
##                 |     0.655 |     0.345 |           | 
## ----------------|-----------|-----------|-----------|
## 
## 
```


分别得到TN = 71,TP = 39, FN=1,FP=0。因此：

accuracy = (TN+TP)/100=97.345%  
sensitivity=TP/(TP+FN)= 92.86%  
Specificity=TN/(TN+FP)= 100%  

详细解释可以看wikipedia [Sensitivity and specificity](http://en.wikipedia.org/wiki/Sensitivity_and_specificity)。简单说sensitivity是检查正确识别恶性肿瘤的比例，Specificity检查正确排除恶性肿瘤的比例。

## 模型改进

前面我们采用的是最大最小标准化，还可以用z-score来实验一次。最大最小值标准化强制把数据压缩在了0～1之间，也许减小了极值的影响，不过可能极值正好是恶性的标志呢？以下采用z-score重复前面的步骤：


```r
wdbc_z = as.data.frame(scale(wdbc[-1]))
summary(wdbc_z$Area_mean)
```

```
##    Min. 1st Qu.  Median    Mean 3rd Qu.    Max. 
##  -0.737  -0.494  -0.347   0.000   0.107  11.000
```

```r
set.seed(2014)
inTrain = createDataPartition(y = wdbc$diagnosis, p = 0.8, list = FALSE)
wdbc_train = wdbc_z[inTrain, ]
wdbc_test = wdbc_z[-inTrain, ]
wdbc_train_label = wdbc[inTrain, 1]
wdbc_test_label = wdbc[-inTrain, 1]
wdbc_test_pred = knn(train = wdbc_train, test = wdbc_test, cl = wdbc_train_label, 
    k = 21)
CrossTable(x = wdbc_test_label, y = wdbc_test_pred, prop.chisq = FALSE)
```

```
## 
##  
##    Cell Contents
## |-------------------------|
## |                       N |
## |           N / Row Total |
## |           N / Col Total |
## |         N / Table Total |
## |-------------------------|
## 
##  
## Total Observations in Table:  113 
## 
##  
##                 | wdbc_test_pred 
## wdbc_test_label |    Benign | Malignant | Row Total | 
## ----------------|-----------|-----------|-----------|
##          Benign |        71 |         0 |        71 | 
##                 |     1.000 |     0.000 |     0.628 | 
##                 |     0.947 |     0.000 |           | 
##                 |     0.628 |     0.000 |           | 
## ----------------|-----------|-----------|-----------|
##       Malignant |         4 |        38 |        42 | 
##                 |     0.095 |     0.905 |     0.372 | 
##                 |     0.053 |     1.000 |           | 
##                 |     0.035 |     0.336 |           | 
## ----------------|-----------|-----------|-----------|
##    Column Total |        75 |        38 |       113 | 
##                 |     0.664 |     0.336 |           | 
## ----------------|-----------|-----------|-----------|
## 
## 
```


我们发现z-score的效果比之前的差:

accuracy = (TN+TP)/113=96.46%  
sensitivity=TP/(TP+FN)= 90.47%  
Specificity=TN/(TN+FP)= 100%  

此外我们还可以调整k，这里就不重复了。


